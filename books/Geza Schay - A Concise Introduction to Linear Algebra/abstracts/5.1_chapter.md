# Chapter 5.1: Orthogonal Projections and Least-Squares Approximations

---

## Main Idea

- This subchapter introduces the method of **least squares** to solve inconsistent linear systems (where no exact solution exists) by finding the "best possible" approximate solution that minimizes error.

- It explains that this best approximation is geometrically found by **orthogonally projecting** the target vector onto the subspace spanned by the available data (the Column Space), a technique essential for fitting curves to data points in computer graphics and physics simulations.

---

## Keywords

**Orthogonal Projection ($q$):**

- The specific vector inside a subspace $V$ that is closest to a given external vector $p$; the error vector ($p-q$) is perpendicular (orthogonal) to the subspace.

**Least-Squares Solution:**

- The input vector $x$ that minimizes the square of the distance between the actual output $Ax$ and the desired output $p$ (minimizing $|Ax - p|^2$).

**Normal Equations:**

- A transformed version of the original system ($A^T Ax = A^T p$) that is guaranteed to be consistent (solvable) and yields the least-squares solution.

**Projection Matrix ($P$):**

- A square matrix that maps any vector onto a specific subspace; it must be **symmetric** ($P^T = P$) and **idempotent** ($P^2 = P$, meaning applying it twice changes nothing).

---

## Formulas

**Normal Equations**

- **Formula:** $A^T A x = A^T p$

- **Meaning:** To solve an impossible system $Ax=p$, multiply both sides by the transpose $A^T$ to create a solvable system.

- **Use in graphics:** Finding the best-fit coefficients for a geometric primitive (like a line or plane) through noisy data points.

**Projection Matrix**

- **Formula:** $P = A(A^T A)^{-1} A^T$

- **Meaning:** The matrix operator that squashes any vector directly down onto the column space of $A$.

- **Use in graphics:** Calculating shadows (projecting geometry onto a ground plane).

**Least-Squares Error (Line Fitting)**

- **Formula:** $f(a, b) = \sum_{i=1}^{m} (ax_i + b - y_i)^2$

- **Meaning:** The sum of the squared vertical distances between data points and the fitted line.

- **Use in graphics:** Validating how well a simplified model matches the original high-resolution data.

---

## Practical Use

**Curve Fitting (Regression)**

- Drawing the "best fit" straight line or polynomial through a cloud of scattered points (e.g., predicting a projectile's path based on noisy sensor readings).

**Geometric Approximation**

- Finding the point on a plane that is closest to a specific 3D point, which is used for collision detection (shortest distance to a surface).

**Signal Reconstruction**

- Reconstructing a clean signal (vector) from noisy data by projecting the noisy vector onto a subspace defined by smooth basis functions.
