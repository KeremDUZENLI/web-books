### Answer 8.2.6

**a. Symmetric Matrix Condition Number:**
For a symmetric matrix $A$, the condition number (using 2-norm) is $c = \frac{|\lambda_{max}|}{|\lambda_{min}|}$.
Since $|\lambda_{max}| \ge |\lambda_{min}|$, the ratio is always $\ge 1$.

**b. Symmetric $2 \times 2$ with $c=1$:**
Requires $|\lambda_1| = |\lambda_2|$.
Case 1: $\lambda_1 = \lambda_2 = k$. $A = kI$. (Scalar matrices).
Case 2: $\lambda_1 = -\lambda_2 = k$. Trace is 0.
$A = \begin{bmatrix} a & b \\ b & -a \end{bmatrix}$ with $a^2+b^2 = k^2$.

**c. Condition Number (Eq 8.36):**
$A = \begin{bmatrix} 0.001 & 1 \\ 1 & 1 \end{bmatrix}$.
Eigenvalues: $\lambda^2 - 1.001\lambda - 0.999 = 0$.
$\lambda \approx 1.618, -0.617$ (rough).
Better: Singular values. Or use infinity norm condition number.
$A^{-1} \approx \begin{bmatrix} -1 & 1 \\ 1 & 0 \end{bmatrix}$.
$||A||_\infty = 2$. $||A^{-1}||_\infty = 2$.
Cond $\approx 4$ (well conditioned).
Wait, problem 8.2.1 used 0.002 and had issues. The issue was *pivoting*, not the condition number itself. A matrix can be well-conditioned but require pivoting for stability.

**d. Condition Number (Eq 8.40):**
$A' = \begin{bmatrix} 1 & 1 \\ 0.001 & 1 \end{bmatrix}$.
Clearly well conditioned.

**e. Conclusion:**
Small pivots do not imply a large condition number (bad conditioning).
Instability in Gaussian elimination (without pivoting) can occur even for well-conditioned matrices if a small pivot is chosen.
Condition number measures sensitivity to input errors; Pivoting handles stability of the algorithm.