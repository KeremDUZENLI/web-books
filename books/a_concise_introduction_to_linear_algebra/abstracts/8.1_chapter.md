# Chapter 8.1: LU Factorization

---

## Main Idea

- This subchapter introduces **LU Factorization**, a method of decomposing a matrix $A$ into the product of a lower triangular matrix $L$ and an upper triangular matrix $U$.

- This technique is a variation of Gaussian elimination that separates the coefficient matrix processing from the right-hand side vector. It is highly efficient for solving systems of linear equations ($Ax=b$) when the same matrix $A$ is used with multiple different vectors $b$.

---

## Keywords

**Lower Triangular Matrix ($L$):**

- A square matrix where all entries above the main diagonal are zero. In LU factorization, $L$ typically has 1s on its main diagonal.

**Upper Triangular Matrix ($U$):**

- A square matrix where all entries below the main diagonal are zero. This corresponds to the echelon form obtained from Gaussian elimination.

**LU Factorization:**

- The representation of a matrix $A$ as $A = LU$. This effectively "stores" the steps of Gaussian elimination ($L$ stores the multipliers, $U$ stores the result).

**LDU Factorization:**

- A variation where $A$ is written as $LDU$, separating the pivots into a distinct diagonal matrix $D$, leaving $U$ with 1s on its diagonal.

---

## Formulas

**The Factorization**

- **Formula:** $A = LU$

- **Meaning:** Any square matrix $A$ (that doesn't require row exchanges) can be written as a lower triangular matrix times an upper triangular matrix.

**Solving the System**

- **Step 1 (Forward Substitution):** Solve $Lc = b$ for $c$.

- **Step 2 (Back Substitution):** Solve $Ux = c$ for $x$.

- **Meaning:** Instead of solving one complex system $Ax=b$, you solve two simple triangular systems.

**Constructing L**

- **Formula:** $l_{ij}$ is the multiplier used to eliminate $a_{ij}$.

- **Meaning:** The entry in the $i$-th row and $j$-th column of $L$ is exactly the multiple of row $j$ subtracted from row $i$ during elimination.

---

## Practical Use

**Multiple Right-Hand Sides**

- If you need to solve $Ax=b$ for many different $b$ vectors (e.g., simulating a structure under different load conditions), you compute $L$ and $U$ once ($O(n^3)$ operations) and then solve for each $b$ very quickly ($O(n^2)$ operations).

**Computational Efficiency**

- For large $n$, solving triangular systems is much faster than full elimination. This separation of "hard work" (factorization) from "easy work" (substitution) is standard in numerical software.

**Inverting Matrices**

- To compute $A^{-1}$, one solves $Ax_i = e_i$ for each standard basis vector. LU factorization makes this repeated solving process significantly faster.
